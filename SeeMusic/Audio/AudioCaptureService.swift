import Foundation
import ScreenCaptureKit
import AVFoundation
import Combine

// éŸ³é¢‘æ•è·æœåŠ¡ - ä½¿ç”¨ ScreenCaptureKit æ•è·ç³»ç»ŸéŸ³é¢‘
@MainActor
class AudioCaptureService: NSObject, ObservableObject, SCStreamDelegate {
    static let shared = AudioCaptureService()
    
    @Published var isCapturing = false
    @Published var currentFeatures: AudioFeatures = .zero
    
    private var stream: SCStream?
    private var streamOutput: AudioStreamOutput?
    private var screenOutput: ScreenStreamOutput?
    private let featureExtractor = FeatureExtractor()
    private let featurePipeline = FeaturePipeline()
    private var isStarting = false
    
    override init() {
        super.init()
    }
    
    // å¼€å§‹æ•è·
    func start() async {
        guard !isCapturing && !isStarting else {
            print("[SeeMusic] âš ï¸ å·²åœ¨æ•è·ä¸­æˆ–æ­£åœ¨å¯åŠ¨ï¼Œè·³è¿‡")
            return
        }
        
        isStarting = true
        featurePipeline.reset()
        
        do {
            print("[SeeMusic] ğŸ“¡ è·å–å±å¹•ä¿¡æ¯...")
            let content = try await SCShareableContent.excludingDesktopWindows(false, onScreenWindowsOnly: true)
            
            guard let display = content.displays.first else {
                print("[SeeMusic] âŒ æœªæ‰¾åˆ°æ˜¾ç¤ºå™¨")
                isStarting = false
                return
            }
            
            print("[SeeMusic] ğŸ–¥ï¸ ä½¿ç”¨æ˜¾ç¤ºå™¨: \(display.displayID), å°ºå¯¸: \(display.width)x\(display.height)")
            
            // åˆ›å»ºå†…å®¹è¿‡æ»¤å™¨
            let filter = SCContentFilter(display: display, excludingWindows: [])
            
            // é…ç½®æµ - å…³é”®æ˜¯è¦è®¾ç½®åˆç†çš„è§†é¢‘å‚æ•°
            let config = SCStreamConfiguration()
            
            // éŸ³é¢‘è®¾ç½®
            config.capturesAudio = true
            config.excludesCurrentProcessAudio = false
            config.sampleRate = 48000
            config.channelCount = 2
            
            // è§†é¢‘è®¾ç½® - éœ€è¦è®¾ç½®åˆç†çš„å°ºå¯¸ï¼Œä¸èƒ½å¤ªå°
            config.width = 2
            config.height = 2
            config.minimumFrameInterval = CMTime(value: 1, timescale: 1) // 1 FPS
            config.showsCursor = false
            config.pixelFormat = kCVPixelFormatType_32BGRA
            
            print("[SeeMusic] ğŸ“ åˆ›å»º SCStream...")
            
            // åˆ›å»ºæµï¼ˆä½¿ç”¨ self ä½œä¸º delegateï¼‰
            let newStream = SCStream(filter: filter, configuration: config, delegate: self)
            
            // è®¾ç½®éŸ³é¢‘è¾“å‡º
            let output = AudioStreamOutput { [weak self] buffer in
                Task { @MainActor in
                    self?.processAudioBuffer(buffer)
                }
            }
            
            print("[SeeMusic] ğŸ”Œ æ·»åŠ éŸ³é¢‘è¾“å‡º...")
            try newStream.addStreamOutput(output, type: .audio, sampleHandlerQueue: DispatchQueue(label: "com.seemusic.audio", qos: .userInteractive))

            let videoOutput = ScreenStreamOutput()
            try newStream.addStreamOutput(videoOutput, type: .screen, sampleHandlerQueue: DispatchQueue(label: "com.seemusic.screen", qos: .utility))
            
            // ä¿å­˜å¼•ç”¨
            self.stream = newStream
            self.streamOutput = output
            self.screenOutput = videoOutput
            
            print("[SeeMusic] â–¶ï¸ å¯åŠ¨æ•è·...")
            try await newStream.startCapture()
            
            isCapturing = true
            isStarting = false
            
            print("[SeeMusic] âœ… éŸ³é¢‘æ•è·å·²æˆåŠŸå¯åŠ¨ï¼")
            print("[SeeMusic] ğŸ“Š é…ç½®: é‡‡æ ·ç‡=\(config.sampleRate), å£°é“=\(config.channelCount)")
            
        } catch {
            print("[SeeMusic] âŒ éŸ³é¢‘æ•è·å¯åŠ¨å¤±è´¥: \(error)")
            print("[SeeMusic] ğŸ“‹ é”™è¯¯è¯¦æƒ…: \(error.localizedDescription)")
            isCapturing = false
            isStarting = false
            stream = nil
            streamOutput = nil
            screenOutput = nil
        }
    }
    
    // åœæ­¢æ•è·
    func stop() async {
        guard isCapturing else { return }
        
        do {
            try await stream?.stopCapture()
            stream = nil
            streamOutput = nil
            screenOutput = nil
            isCapturing = false
            featurePipeline.reset()
            print("[SeeMusic] â¹ï¸ éŸ³é¢‘æ•è·å·²åœæ­¢")
        } catch {
            print("[SeeMusic] âŒ åœæ­¢æ•è·å¤±è´¥: \(error)")
        }
    }
    
    // SCStreamDelegate
    nonisolated func stream(_ stream: SCStream, didStopWithError error: Error) {
        print("[SeeMusic] âš ï¸ æµåœæ­¢: \(error.localizedDescription)")
        Task { @MainActor in
            self.isCapturing = false
            self.stream = nil
            self.streamOutput = nil
            self.screenOutput = nil
            self.featurePipeline.reset()
        }
    }
    
    // å¤„ç†éŸ³é¢‘ buffer
    // private var logCounter = 0
    private func processAudioBuffer(_ buffer: CMSampleBuffer) {
        let rawFeatures = featureExtractor.extractFeatures(from: buffer)
        let params = FeaturePipeline.Parameters(
            rmsGain: Float(Config.shared.rmsGain),
            lowGain: Float(Config.shared.lowGain),
            beatDiffGain: Float(Config.shared.beatBoost),
            rmsAttackMs: Config.shared.rmsAttackMs,
            rmsReleaseMs: Config.shared.rmsReleaseMs,
            lowAttackMs: Config.shared.lowAttackMs,
            lowReleaseMs: Config.shared.lowReleaseMs
        )
        let processed = featurePipeline.process(rawFeatures, parameters: params)
        currentFeatures = processed
        
        // logCounter += 1
        // if logCounter >= 60 {
        //     logCounter = 0
        //     print("[SeeMusic] ğŸµ éŸ³é¢‘: RMS=\(String(format: "%.4f", processed.rms)), Low=\(String(format: "%.4f", processed.lowEnergy))")
        // }
    }
}

// éŸ³é¢‘æµè¾“å‡ºå¤„ç†å™¨
class AudioStreamOutput: NSObject, SCStreamOutput {
    private let handler: (CMSampleBuffer) -> Void
    
    init(handler: @escaping (CMSampleBuffer) -> Void) {
        self.handler = handler
    }
    
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard type == .audio else { return }
        handler(sampleBuffer)
    }
}

// ä»…ç”¨äºæ¶ˆåŒ–è§†é¢‘å¸§ï¼Œé¿å… SCStream æŠ¥é”™
class ScreenStreamOutput: NSObject, SCStreamOutput {
    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard type == .screen else { return }
    }
}
